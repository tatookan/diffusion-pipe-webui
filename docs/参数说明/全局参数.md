### 全局配置参数 (Top-level)

这些参数直接写在文件顶部，不属于任何 `[...]` 块。

| 参数 | 功能 | 默认值 | 推荐设置/说明 | | :--- | :--- | :--- | :--- | | `dataset` | __(必需)__ 指向数据集配置 `.toml` 文件的路径。 | 无 | 例如: `"examples/my_dataset.toml"` | | `epochs` / `steps` | __(必需)__ 训练的总轮数或总步数。 | 无 | 根据您的数据集大小和期望的训练程度设置。 | | `output_dir` | __(必需)__ 保存模型、日志和检查点的根目录。 | 无 | 例如: `"/mnt/my_lora_output"` | | `micro_batch_size_per_gpu` | 每个 GPU 在一次前向/反向传播中处理的样本数。 | `1` | 通常保持为 `1` 以节省显存。通过 `gradient_accumulation_steps` 来实现更大的有效批量大小。 | | `gradient_accumulation_steps` | 梯度累积步数。有效批量大小 = `micro_batch_size_per_gpu` * `gradient_accumulation_steps` * GPU数量。 | `1` | 这是调节批量大小和显存占用的关键参数。`4` 到 `16` 是常见值。 | | `learning_rate` | 学习率。 | 无 | __(必需)__ 常用值为 `"1e-4"`, `"2e-4"`, `"1e-5"`。需要根据实验调整。 | | `save_every_n_steps` / `save_every_n_epochs` | __(必需)__ 每隔多少步或多少轮保存一次模型。两者至少要提供一个。 | 无 | `1000` 步或 `1` 轮是常见的起点。 | | `save_dtype` | 保存模型时使用的数据类型。 | 模型原始 `dtype` | 可选值为 `"float32"`, `"bfloat16"`, `"float16"`。使用 `"bfloat16"` 或 `"float16"` 可以节省大量磁盘空间。 | | `activation_checkpointing` | 是否启用梯度检查点以节省显存。 | `false` | 当遇到显存不足时，设置为 `true`。会稍微降低训练速度。 | | `reentrant_activation_checkpointing` | 梯度检查点的具体实现方式。 | `false` | 设为 `true` 可能与某些库（如 unsloth）的兼容性更好。通常保持默认即可。 | | `warmup_steps` | 学习率预热步数。在前 N 步内，学习率从 0 线性增长到设定值。 | `0` | 设置为总步数的 5-10% (例如 `200`) 有助于训练初期的稳定。 | | `logging_steps` | 每隔多少步在终端和 TensorBoard 中记录一次 loss。 | `1` | `10` 或 `50` 是常见值，避免日志过于频繁。 | | `gradient_clipping` | 梯度裁剪的阈值，防止梯度爆炸。 | `1.0` | 通常保持默认值 `1.0`。 | | `uncond_fraction` | 在训练中以一定概率丢弃文本提示，进行无条件训练。 | `0.0` | 对于 LoRA 微调，通常保持 `0.0`。在从头预训练时可能会使用 `0.1` 等值。 | | `map_num_proc` | 在数据预处理（缓存）阶段使用的 CPU 核心数。 | (自动检测) | 如果您的 CPU 核心数很多，可以手动设置为 `8`, `16` 等来加速数据缓存。 | | `blocks_to_swap` | (高级) 启用 Block Swapping 以节省显存，将模型层在 CPU 和 GPU 间交换。 | `0` | 仅在显存极度紧张时使用，会显著降低训练速度。需要 LoRA 训练和 `pipeline_stages=1`。 | | `pipeline_stages` | (高级) 流水线并行阶段数，用于多 GPU 训练。 | `1` | 如果您有多张卡，可以设为 GPU 数量，将模型切分到不同卡上以节省单卡显存。 | | `compile` | (实验性) 是否使用 `torch.compile` 来加速模型。 | `false` | 可以尝试设为 `true`，但可能不稳定或在某些模型上无效。 |

---

### 评估相关参数 (Top-level)

| 参数 | 功能 | 默认值 | 推荐设置/说明 | | :--- | :--- | :--- | :--- | | `eval_datasets` | 用于评估的验证数据集列表。 | `[]` (空列表) | `eval_datasets = [{name = "eval1", config = "examples/my_eval_dataset.toml"}]` | | `eval_every_n_steps` / `eval_every_n_epochs` | 每隔多少步或多少轮进行一次评估。 | `None` | 如果配置了 `eval_datasets`，则需要设置其中一个。 | | `eval_gradient_accumulation_steps` | 评估时的梯度累积步数。 | `1` | 通常保持为 `1`。 | | `eval_before_first_step` | 是否在训练开始前进行一次评估，以获取基线性能。 | `true` | 建议保持 `true`。 |

---

### 模型配置 `[model]`

这部分参数与您选择的具体模型 (`type`) 强相关。以我们使用的 `flux` 为例：

| 参数 | 功能 | 默认值 | 推荐设置/说明 | | :--- | :--- | :--- | :--- | | `type` | __(必需)__ 模型类型。 | 无 | 例如: `"flux"`, `"sdxl"` | | `diffusers_path` | __(必需)__ 指向基础模型的 Diffusers 格式文件夹。 | 无 | 例如: `"/path/to/FLUX.1-dev"` | | `transformer_path` | (可选) 指向特定 `.safetensors` 文件的路径，用于覆盖基础模型中的 Transformer。 | `None` | 在我们的例子中，用于加载 `Kontext` 版本的 Transformer。 | | `dtype` | __(必需)__ 模型的主要数据类型。 | 无 | `"bfloat16"` (推荐用于 Ampere 及更新架构的 GPU), `"float16"` (通用)。 | | `transformer_dtype` | (可选) 单独为 Transformer 设置数据类型，以节省显存。 | `dtype` 的值 | 可选值为 `"float8"`。仅在 LoRA 训练且显存非常紧张时考虑。 | | `flux_shift` | (Flux 特有) 是否启用分辨率相关的 timestep shift，一种训练技巧。 | `false` | 文档中推荐为 `true`，可以尝试开启。 | | `bypass_guidance_embedding` | (Flux 特有) 是否绕过 guidance embedding。 | `false` | 仅针对特定版本的 Flux 模型（如 FLEX.1-alpha）推荐开启。 |

---

### 优化器配置 `[optimizer]`

| 参数 | 功能 | 默认值 | 推荐设置/说明 | | :--- | :--- | :--- | :--- | | `type` | __(必需)__ 优化器类型。 | 无 | `"adamw8bit"` (节省显存), `"adamw"` (标准) 是最常用的。脚本还支持 `prodigy`, `lion` 等多种类型。 | | `lr` | 学习率。 | (从全局读取) | 通常在全局设置，但也可以在这里为特定参数组覆盖。 | | `betas` | AdamW 优化器的 beta 参数。 | `[0.9, 0.999]` | 通常保持默认。 | | `weight_decay` | 权重衰减。 | `0.01` | 通常保持默认。 | | `eps` | AdamW 优化器的 epsilon 参数。 | `1e-8` | 通常保持默认。 |

---

### LoRA 适配器配置 `[adapter]`

| 参数 | 功能 | 默认值 | 推荐设置/说明 | | :--- | :--- | :--- | :--- | | `type` | __(必需)__ 适配器类型。 | 无 | 目前只支持 `"lora"`。 | | `rank` | __(必需)__ LoRA 的秩。 | 无 | `8`, `16`, `32` 是常见值。越高的 rank 学习能力越强，但参数量也越大。 | | `lora_dropout` | LoRA 层的 Dropout 概率。 | `0.0` | `0.05` 或 `0.1` 是常见值，有助于防止过拟合。 | | `init_from_existing` | (可选) 从一个已有的 LoRA 文件初始化权重，而不是随机初始化。 | `None` | 用于在已有的 LoRA 上继续训练。 |
